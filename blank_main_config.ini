[Default]
task=  # Task to perform, to sample from [study, validation]
data_root=  # Path to the folder containing the raw dataset, organized according to the guidelines from the README.md
number_processes= # Number of processes to use in parallel for computation

[Studies]
input_folder=  # Path to the folder containing the results from the Validation step (i.e., output_folder from [Validation])
output_folder=  # Path to the folder where the study results will be stored (will be created if non-existing)
task=  # String indicating the study task, to sample from [segmentation] (cf. Studies/study_connector.py)
class_names=  # List of strings with the names of the segmented classes to report
extra_parameters_filename=  # Path to a csv file containing additional information for each patient (e.g., image spacing)
selections_dense=  # List of strings separated with '\'. Each string should contain: the first metric name, the second metric name, threshold values for the second metric separated by '-', a category from [All, True Positive]. Example: PiW Dice,GT volume (ml),4,All\IOU,GT volume (ml),4,All
selections_categorical=  # Same as above, except that the second metric should be categorical. For example, MR sequence types with values [T1, T2, FLAIR].

[Validation]
input_folder=  # Path to the folder containing the prediction files from your model
output_folder=  # Path to the folder where the validation results should be stored (will be created if non-existing)
gt_files_suffix= # Comma-separated list of strings for each class suffix, including file extension type (e.g., label_tumor.nii.gz)
prediction_files_suffix=  # Comma-separated list of strings for each class suffix, including file extension type (e.g., pred_tumor.nii.gz)
use_index_naming_convention=  # Boolean to indicate if the file naming convention with folder indexes is followed
nb_folds=  # Integer value indicating the number of folds in the k-fold cross-validation
split_way=  # String sampled from [two-way, three-way], to indicate if a train/val (two-way) or train/val/test (three-way) split is used for the k-fold cross-validation
detection_overlap_thresholds=  # Comma-separated list of float, one value for each class, to indicate the minimum Dice overlap value for a segmentation to be considered valid
metrics_space=  # Comma-separated list of spaces where to compute the metrics, to sample from: [pixelwise, patientwise, objectwise]
extra_metrics=  # Comma-separated list of metrics to compute, to sample from [TPR, TNR, FPR, FNR, PPV, Jaccard, IOU, AUC, VS, VC, RAVD, GCE, MI, MCC, CKS, VOI, ARI, ASSD, HD95, MahaD, ProbD, OASSD]
class_names=  # Comma-separated list of strings with the names of each segmented class
tiny_objects_removal_threshold= # Integer representing the minimum number of voxels an object must have to be kept as an object
true_positive_volume_thresholds=  # Comma-separated list of float for cut-off values to apply to each class to consider them as true positives or not
